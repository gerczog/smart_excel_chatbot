import os
import pandas as pd
import re
from typing import Dict, List, Optional, Tuple, Any
from functools import lru_cache
from dotenv import load_dotenv
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate

# Load environment variables
load_dotenv()


class SmartExcelChatbot:
    """
    –£–º–Ω—ã–π —á–∞—Ç-–±–æ—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel —Ñ–∞–π–ª–∞–º–∏
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª–∏—Å—Ç—ã –∏ –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
    """

    def __init__(self, file_path: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç-–±–æ—Ç–∞

        Args:
            file_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        self.file_path = file_path
        self.excel_file = pd.ExcelFile(file_path)
        self.sheet_names = self.excel_file.sheet_names
        self.dataframes = {}
        self.agents = {}
        self.combined_df = None  # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤
        self.combined_agent = None  # –ê–≥–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        self.context = {}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –≤ .env —Ñ–∞–π–ª–µ.")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
        self.llm = ChatOpenAI(temperature=0, model="gpt-4o-mini")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
        self._load_all_sheets()
        self._create_combined_dataframe()
        self._analyze_structure()

    def _load_all_sheets(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –ª–∏—Å—Ç—ã –∏–∑ Excel —Ñ–∞–π–ª–∞"""
        for sheet_name in self.sheet_names:
            try:
                df = pd.read_excel(self.file_path, sheet_name=sheet_name, parse_dates=True, date_format='%Y-%m-%d')
                if not df.empty:
                    self.dataframes[sheet_name] = df
                    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
                    self.agents[sheet_name] = create_pandas_dataframe_agent(
                        self.llm,
                        df,
                        verbose=False,
                        agent_type=AgentType.OPENAI_FUNCTIONS,
                        allow_dangerous_code=True
                    )
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–∏—Å—Ç–∞ {sheet_name}: {e}")

    def _create_combined_dataframe(self):
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        combined_data = []

        for sheet_name, df in self.dataframes.items():
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ä–µ–≥–∏–æ–Ω–∞
            df_copy = df.copy()
            df_copy['–†–µ–≥—ñ–æ–Ω'] = sheet_name

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
            combined_data.append(df_copy)

        if combined_data:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ DataFrame
            self.combined_df = pd.concat(combined_data, ignore_index=True)

            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            self.combined_agent = create_pandas_dataframe_agent(
                self.llm,
                self.combined_df,
                verbose=False,
                agent_type=AgentType.OPENAI_FUNCTIONS,
                allow_dangerous_code=True
            )

            print(
                f"‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame —Å {len(self.combined_df)} –∑–∞–ø–∏—Å—è–º–∏ –∏–∑ {len(self.dataframes)} —Ä–µ–≥–∏–æ–Ω–æ–≤")
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

    def _analyze_column_semantics(self, column_name: str, sample_data: list, data_type: str) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ –∏ –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è LLM
        
        Args:
            column_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
            sample_data: –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–ª–æ–Ω–∫–∏
            data_type: –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–ª–æ–Ω–∫–µ
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–æ–Ω–∫–∏
            prompt = ChatPromptTemplate.from_messages([
                SystemMessage(content="""
                –¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å:
                1. –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ç–∞ –∫–æ–ª–æ–Ω–∫–∞ (–Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º —è–∑—ã–∫–µ)
                2. –ö–∞–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –º–æ–∂–Ω–æ —Å –Ω–µ–π –≤—ã–ø–æ–ª–Ω—è—Ç—å
                3. –ö–∞–∫ –æ–Ω–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
                4. –í–æ–∑–º–æ–∂–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
                
                –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
                {
                  "meaning": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∞",
                  "operations": ["—Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"],
                  "business_context": "–±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
                  "units": "–µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)",
                  "category": "–∫–∞—Ç–µ–≥–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö (—Ñ–∏–Ω–∞–Ω—Å—ã, –¥–∞—Ç—ã, —Ç–æ–≤–∞—Ä—ã, –∫–ª–∏–µ–Ω—Ç—ã –∏ —Ç.–¥.)"
                }
                """),
                HumanMessage(content=f"""
                –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏: "{column_name}"
                –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {data_type}
                –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π: {sample_data[:5]}
                """)
            ])
            
            response = self.llm.invoke(prompt)
            
            # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç
            try:
                import json
                semantic_info = json.loads(response.content.strip())
                return semantic_info
            except:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                return {
                    "meaning": f"–ö–æ–ª–æ–Ω–∫–∞ '{column_name}' —Ç–∏–ø—É {data_type}",
                    "operations": ["–±–∞–∑–æ–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó"],
                    "business_context": "–∑–∞–≥–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                    "units": "–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–æ",
                    "category": "–∑–∞–≥–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ"
                }
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            return {
                "meaning": f"–ö–æ–ª–æ–Ω–∫–∞ '{column_name}'",
                "operations": ["–±–∞–∑–æ–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó"],
                "business_context": "–∑–∞–≥–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                "units": "",
                "category": "–¥–∞–Ω—ñ"
            }

    def _analyze_structure(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        print("üîç –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")

        self.context = {
            "file_path": self.file_path,
            "total_sheets": len(self.sheet_names),
            "sheets_info": {},
            "global_analysis": {},
            "column_semantics": {}  # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
        }

        all_columns = set()
        all_data_types = {}
        total_rows = 0
        file_size = os.path.getsize(self.file_path) / (1024 * 1024)  # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ –ú–ë

        print(f"üìä –§–∞–π–ª: {os.path.basename(self.file_path)}")
        print(f"üìè –†–∞–∑–º–µ—Ä: {file_size:.2f} –ú–ë")
        print(f"üìã –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç–æ–≤: {len(self.sheet_names)}")
        print(f"üèôÔ∏è –õ–∏—Å—Ç—ã: {', '.join(self.sheet_names)}")

        for sheet_name in self.sheet_names:
            if sheet_name in self.dataframes:
                df = self.dataframes[sheet_name]
                total_rows += len(df)

                print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –ª–∏—Å—Ç–∞ '{sheet_name}':")
                print(f"  - –°—Ç—Ä–æ–∫: {len(df)}")
                print(f"  - –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
                print(f"  - –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

                # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
                sheet_info = {
                    "columns": df.columns.tolist(),
                    "rows": len(df),
                    "data_types": {str(col): str(dtype) for col, dtype in df.dtypes.items()},
                    "sample_data": [],  # –ë—É–¥–µ–º –∑–∞–ø–æ–ª–Ω—è—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ
                    "column_analysis": {},
                    "unique_values": {},
                    "date_columns": [],
                    "numeric_columns": [],
                    "text_columns": [],
                    "missing_values": {},
                    "column_formats": {},
                    "data_quality": {}
                }

                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–ø–æ–ª–Ω—è–µ–º sample_data
                for idx, row in df.head(3).iterrows():
                    row_data = {}
                    for col in df.columns:
                        value = row[col]
                        if isinstance(value, bool):
                            row_data[col] = str(value)
                        elif pd.isna(value):
                            row_data[col] = None
                        else:
                            row_data[col] = value
                    sheet_info["sample_data"].append(row_data)

                # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
                for col in df.columns:
                    col_str = str(col)
                    all_columns.add(col_str)

                    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    missing_count = df[col].isnull().sum()
                    missing_percent = (missing_count / len(df)) * 100
                    sheet_info["missing_values"][col_str] = {
                        "count": int(missing_count),
                        "percent": float(missing_percent)
                    }

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–ª–æ–Ω–∫–∏
                    col_type = "text"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Ç–∏–ø—ã
                    if pd.api.types.is_numeric_dtype(df[col]):
                        sheet_info["numeric_columns"].append(col_str)
                        col_type = "numeric"
                    # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º datetime —Ç–∏–ø—ã
                    elif pd.api.types.is_datetime64_any_dtype(df[col]):
                        sheet_info["date_columns"].append(col_str)
                        col_type = "datetime"
                    else:
                        # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –æ–Ω–∏ –¥–∞—Ç—ã
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —á–∏—Å–ª–æ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞
                            sample_data = df[col].dropna().head(10)
                            if len(sample_data) > 0:
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∞—Ç –ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–∞—Ç
                                sample_str = str(sample_data.iloc[0])
                                if (len(sample_str) >= 8 and 
                                    ('-' in sample_str or '/' in sample_str) and
                                    any(char.isdigit() for char in sample_str)):
                                    
                                    test_conversion = pd.to_datetime(sample_data, errors='coerce')
                                    # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 80% –∑–Ω–∞—á–µ–Ω–∏–π —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã - —ç—Ç–æ –¥–∞—Ç–∞
                                    if test_conversion.notna().sum() / len(test_conversion) > 0.8:
                                        sheet_info["date_columns"].append(col_str)
                                        col_type = "datetime"
                                    else:
                                        sheet_info["text_columns"].append(col_str)
                                        col_type = "text"
                                else:
                                    sheet_info["text_columns"].append(col_str)
                                    col_type = "text"
                            else:
                                sheet_info["text_columns"].append(col_str)
                                col_type = "text"
                        except:
                            sheet_info["text_columns"].append(col_str)
                            col_type = "text"

                    # –ê–Ω–∞–ª–∏–∑ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    unique_count = df[col].nunique()
                    total_count = len(df)
                    sheet_info["unique_values"][col_str] = {
                        "unique_count": unique_count,
                        "total_count": total_count,
                        "unique_ratio": unique_count / total_count if total_count > 0 else 0
                    }

                    # –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
                    sheet_info["column_formats"][col_str] = {
                        "dtype": str(df[col].dtype),
                        "type_category": col_type,
                        "has_missing": str(missing_count > 0),  # Convert boolean to string
                        "missing_percent": float(missing_percent)
                    }

                    # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è LLM
                    sample_values_for_analysis = df[col].dropna().head(5).tolist()
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    safe_sample_values = []
                    for val in sample_values_for_analysis:
                        if isinstance(val, bool):
                            safe_sample_values.append(str(val))
                        elif pd.isna(val):
                            safe_sample_values.append("NaN")
                        else:
                            safe_sample_values.append(str(val))
                    
                    # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∞–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∏–∑–±–µ–≥–∞–µ–º –ª–∏—à–Ω–∏—Ö –≤—ã–∑–æ–≤–æ–≤)
                    if len(safe_sample_values) > 0 and col_str not in ['index', 'id', 'ID']:
                        try:
                            semantic_info = self._analyze_column_semantics(col_str, safe_sample_values, col_type)
                            self.context["column_semantics"][f"{sheet_name}_{col_str}"] = semantic_info
                            print(f"    üß† {col_str}: {semantic_info.get('meaning', '–∞–Ω–∞–ª—ñ–∑ –Ω–µ –≤–¥–∞–≤—Å—è')}")
                        except Exception as e:
                            print(f"    ‚ö†Ô∏è –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ {col_str} –Ω–µ —É–¥–∞–ª—Å—è: {e}")
                            # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é —Å–µ–º–∞–Ω—Ç–∏–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                            self.context["column_semantics"][f"{sheet_name}_{col_str}"] = {
                                "meaning": f"–ö–æ–ª–æ–Ω–∫–∞ {col_str}",
                                "operations": ["–±–∞–∑–æ–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó"],
                                "business_context": "–∑–∞–≥–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
                                "units": "",
                                "category": col_type
                            }

                    # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ - –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π
                    if col_str in sheet_info["text_columns"] and unique_count <= 20:
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º sample_values
                        sample_values = df[col].dropna().unique()[:10]
                        safe_sample_values = []
                        for val in sample_values:
                            if isinstance(val, bool):
                                safe_sample_values.append(str(val))
                            else:
                                safe_sample_values.append(val)

                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º most_common
                        most_common_dict = df[col].value_counts().head(5).to_dict()
                        safe_most_common = {}
                        for key, value in most_common_dict.items():
                            if isinstance(key, bool):
                                safe_most_common[str(key)] = int(value)
                            else:
                                safe_most_common[key] = int(value)

                        sheet_info["column_analysis"][col_str] = {
                            "sample_values": safe_sample_values,
                            "most_common": safe_most_common,
                            "avg_length": float(df[col].astype(str).str.len().mean()) if not df[col].empty else 0.0
                        }

                    # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    elif col_str in sheet_info["numeric_columns"]:
                        sheet_info["column_analysis"][col_str] = {
                            "min": float(df[col].min()) if not df[col].empty else None,
                            "max": float(df[col].max()) if not df[col].empty else None,
                            "mean": float(df[col].mean()) if not df[col].empty else None,
                            "median": float(df[col].median()) if not df[col].empty else None,
                            "std": float(df[col].std()) if not df[col].empty else None,
                            "zeros": int((df[col] == 0).sum()),
                            "negative": int((df[col] < 0).sum()) if not df[col].empty else 0
                        }

                    # –î–ª—è –¥–∞—Ç - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                    elif col_str in sheet_info["date_columns"]:
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É –≤ datetime –µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ datetime
                        date_series = df[col]
                        if not pd.api.types.is_datetime64_any_dtype(date_series):
                            date_series = pd.to_datetime(date_series, errors='coerce')
                        
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º weekdays_distribution
                        weekdays_dict = {}
                        if not date_series.empty:
                            valid_dates = date_series.dropna()
                            if not valid_dates.empty:
                                weekdays_series = valid_dates.dt.day_name().value_counts()
                                for day, count in weekdays_series.items():
                                    weekdays_dict[str(day)] = int(count)

                        sheet_info["column_analysis"][col_str] = {
                            "min_date": str(date_series.min()) if not date_series.empty and date_series.notna().any() else None,
                            "max_date": str(date_series.max()) if not date_series.empty and date_series.notna().any() else None,
                            "date_range_days": int((date_series.max() - date_series.min()).days) if not date_series.empty and date_series.notna().any() else 0,
                            "weekdays_distribution": weekdays_dict
                        }

                    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–æ–Ω–∫–µ
                    print(
                        f"    üìã {col_str}: {col_type} ({df[col].dtype}) - {unique_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, {missing_count} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö ({missing_percent:.1f}%)")

                # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                if sheet_info["date_columns"]:
                    sheet_info["date_range"] = {}
                    sheet_info["date_analysis"] = {}
                    for date_col in sheet_info["date_columns"]:
                        date_series = pd.to_datetime(df[date_col], errors='coerce')
                        valid_dates = date_series.dropna()
                        if not valid_dates.empty:
                            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞—Ç
                            sheet_info["date_range"][date_col] = {
                                "start": valid_dates.min().strftime('%Y-%m-%d'),
                                "end": valid_dates.max().strftime('%Y-%m-%d'),
                                "total_days": (valid_dates.max() - valid_dates.min()).days
                            }

                            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Å—è—Ü–∞–º –∏ –≥–æ–¥–∞–º
                            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º records_per_month
                            records_per_month_dict = {}
                            records_per_month_series = valid_dates.dt.strftime('%Y-%m').value_counts()
                            for month_year, count in records_per_month_series.items():
                                records_per_month_dict[str(month_year)] = int(count)

                            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º records_per_year
                            records_per_year_dict = {}
                            records_per_year_series = valid_dates.dt.year.value_counts()
                            for year, count in records_per_year_series.items():
                                records_per_year_dict[int(year)] = int(count)

                            sheet_info["date_analysis"][date_col] = {
                                "years": sorted(valid_dates.dt.year.unique().tolist()),
                                "months": sorted(valid_dates.dt.month.unique().tolist()),
                                "month_names": sorted(valid_dates.dt.strftime('%B').unique().tolist()),
                                "month_year_combinations": sorted(valid_dates.dt.strftime('%Y-%m').unique().tolist()),
                                "records_per_month": records_per_month_dict,
                                "records_per_year": records_per_year_dict
                            }

                            print(
                                f"    üìÖ {date_col}: {valid_dates.min().strftime('%Y-%m-%d')} –¥–æ {valid_dates.max().strftime('%Y-%m-%d')} ({len(valid_dates)} –∑–∞–ø–∏—Å–µ–π)")

                # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
                total_missing = sum(info["count"] for info in sheet_info["missing_values"].values())
                data_quality_score = ((len(df) * len(df.columns)) - total_missing) / (len(df) * len(df.columns)) * 100

                sheet_info["data_quality"] = {
                    "total_missing_values": total_missing,
                    "completeness_score": float(data_quality_score),
                    "columns_with_missing": [col for col, info in sheet_info["missing_values"].items() if
                                             info["count"] > 0],
                    "high_quality_columns": [col for col, info in sheet_info["missing_values"].items() if
                                             info["percent"] < 5],
                    "problematic_columns": [col for col, info in sheet_info["missing_values"].items() if
                                            info["percent"] > 20]
                }

                print(f"    üìä –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {data_quality_score:.1f}% –ø–æ–ª–Ω–æ—Ç—ã")
                if sheet_info["data_quality"]["problematic_columns"]:
                    print(f"    ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(sheet_info['data_quality']['problematic_columns'])}")

                self.context["sheets_info"][sheet_name] = sheet_info

                # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                for col in df.columns:
                    col_str = str(col)
                    if col_str not in all_data_types:
                        all_data_types[col_str] = set()
                    all_data_types[col_str].add(str(df[col].dtype))

        # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        self.context["global_analysis"] = {
            "total_rows": total_rows,
            "all_columns": list(all_columns),
            "common_columns": [col for col in all_columns if len([s for s in self.sheet_names if
                                                                  col in self.context["sheets_info"].get(s, {}).get(
                                                                      "columns", [])]) > 1],
            "column_frequency": {col: len(
                [s for s in self.sheet_names if col in self.context["sheets_info"].get(s, {}).get("columns", [])]) for
                                 col in all_columns},
            "data_types_summary": {col: list(types) for col, types in all_data_types.items()},
            "file_size_mb": float(file_size),
            "total_sheets": len(self.sheet_names),
            "sheets_with_data": len([s for s in self.sheet_names if s in self.dataframes]),
            "average_rows_per_sheet": total_rows / len([s for s in self.sheet_names if s in self.dataframes]) if len(
                [s for s in self.sheet_names if s in self.dataframes]) > 0 else 0,
            "total_columns": len(all_columns),
            "date_columns_count": len([col for col in all_columns if any(
                col in self.context["sheets_info"].get(s, {}).get("date_columns", []) for s in self.sheet_names)]),
            "numeric_columns_count": len([col for col in all_columns if any(
                col in self.context["sheets_info"].get(s, {}).get("numeric_columns", []) for s in self.sheet_names)]),
            "text_columns_count": len([col for col in all_columns if any(
                col in self.context["sheets_info"].get(s, {}).get("text_columns", []) for s in self.sheet_names)])
        }

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É
        print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê:")
        print(f"  üìÅ –§–∞–π–ª: {os.path.basename(self.file_path)} ({file_size:.2f} –ú–ë)")
        print(f"  üìã –õ–∏—Å—Ç–æ–≤: {len(self.sheet_names)}")
        print(f"  üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows:,}")
        print(f"  üìã –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(all_columns)}")
        print(f"  üìÖ –ö–æ–ª–æ–Ω–æ–∫ —Å –¥–∞—Ç–∞–º–∏: {self.context['global_analysis']['date_columns_count']}")
        print(f"  üî¢ –ß–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {self.context['global_analysis']['numeric_columns_count']}")
        print(f"  üìù –¢–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {self.context['global_analysis']['text_columns_count']}")
        print(f"  üîó –û–±—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(self.context['global_analysis']['common_columns'])}")

        if self.context['global_analysis']['common_columns']:
            print(f"  üîó –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(self.context['global_analysis']['common_columns'])}")

        print("‚úÖ –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def _create_enhanced_context(self) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        """
        context = f"""
        üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó EXCEL –§–ê–ô–õ–ê

        üìÅ –§–ê–ô–õ:
        - –ü—É—Ç—å: {self.file_path}
        - –†–∞–∑–º–µ—Ä: {self.context['global_analysis']['file_size_mb']:.2f} –ú–ë
        - –õ–∏—Å—Ç–æ–≤: {self.context['total_sheets']}
        - –õ–∏—Å—Ç–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏: {self.context['global_analysis']['sheets_with_data']}

        üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
        - –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {self.context['global_analysis']['total_rows']:,}
        - –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {self.context['global_analysis']['total_columns']}
        - –°—Ä–µ–¥–Ω–µ–µ —Å—Ç—Ä–æ–∫ –Ω–∞ –ª–∏—Å—Ç: {self.context['global_analysis']['average_rows_per_sheet']:.0f}

        üìã –¢–ò–ü–´ –î–ê–ù–ù–´–•:
        - –ö–æ–ª–æ–Ω–æ–∫ —Å –¥–∞—Ç–∞–º–∏: {self.context['global_analysis']['date_columns_count']}
        - –ß–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {self.context['global_analysis']['numeric_columns_count']}
        - –¢–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {self.context['global_analysis']['text_columns_count']}

        üìã –°–ü–ò–°–û–ö –õ–ò–°–¢–û–í:
        {', '.join(self.sheet_names)}

        üîç –ì–õ–û–ë–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:
        - –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(self.context['global_analysis']['all_columns'])}
        - –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å—Ç—å –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–∏—Å—Ç–∞—Ö): {', '.join(self.context['global_analysis']['common_columns'])}

        üìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ü–û –õ–ò–°–¢–ê–ú:
        """

        for sheet_name, info in self.context["sheets_info"].items():
            context += f"""
        üèôÔ∏è –õ–ò–°–¢: {sheet_name}
        - –°—Ç—Ä–æ–∫: {info['rows']:,}
        - –ö–æ–ª–æ–Ω–æ–∫: {len(info['columns'])}
        - –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {info['data_quality']['completeness_score']:.1f}% –ø–æ–ª–Ω–æ—Ç—ã

        üìä –ö–û–õ–û–ù–ö–ò:
        {', '.join(info['columns'])}

        üß† –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö:"""
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
            for col in info['columns']:
                semantic_key = f"{sheet_name}_{col}"
                if semantic_key in self.context.get("column_semantics", {}):
                    sem_info = self.context["column_semantics"][semantic_key]
                    context += f"""
        üìã {col}:
          ‚Ä¢ –ó–Ω–∞—á–µ–Ω–Ω—è: {sem_info.get('meaning', '–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–æ')}
          ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä—ñ—è: {sem_info.get('category', '–∑–∞–≥–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ')}
          ‚Ä¢ –ë—ñ–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç: {sem_info.get('business_context', '–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–æ')}
          ‚Ä¢ –ú–æ–∂–ª–∏–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó: {', '.join(sem_info.get('operations', ['–±–∞–∑–æ–≤—ñ']))}"""
                    if sem_info.get('units'):
                        context += f"""
          ‚Ä¢ –û–¥–∏–Ω–∏—Ü—ñ –≤–∏–º—ñ—Ä—É: {sem_info.get('units')}"""

            context += f"""

        üî¢ –¢–ò–ü–´ –î–ê–ù–ù–´–• –ò –§–û–†–ú–ê–¢–´:
        """
            for col, dtype in info['data_types'].items():
                missing_info = info['missing_values'].get(col, {})
                missing_text = f" ({missing_info.get('count', 0)} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö, {missing_info.get('percent', 0):.1f}%)" if missing_info.get(
                    'count', 0) > 0 else ""
                context += f"  - {col}: {dtype}{missing_text}\n"

            if info['numeric_columns']:
                context += f"\nüìà –ß–ò–°–õ–û–í–´–ï –ö–û–õ–û–ù–ö–ò: {', '.join(info['numeric_columns'])}\n"
                for col in info['numeric_columns']:
                    if col in info['column_analysis']:
                        stats = info['column_analysis'][col]
                        context += f"  - {col}: min={stats['min']}, max={stats['max']}, —Å—Ä–µ–¥–Ω–µ–µ={stats['mean']:.2f}, std={stats['std']:.2f}\n"
                        if stats['zeros'] > 0:
                            context += f"    (–Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {stats['zeros']})\n"
                        if stats['negative'] > 0:
                            context += f"    (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {stats['negative']})\n"

            if info['date_columns']:
                context += f"\nüìÖ –î–ê–¢–´: {', '.join(info['date_columns'])}\n"
                for col in info['date_columns']:
                    if col in info.get('date_range', {}):
                        date_info = info['date_range'][col]
                        context += f"  - {col}: {date_info['start']} –¥–æ {date_info['end']} ({date_info['total_days']} –¥–Ω–µ–π)\n"

                        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Å—è—Ü–∞—Ö –∏ –≥–æ–¥–∞—Ö
                        if col in info.get('date_analysis', {}):
                            date_analysis = info['date_analysis'][col]
                            context += f"    üìä –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º:\n"
                            context += f"    - –ì–æ–¥—ã: {', '.join(map(str, date_analysis['years']))}\n"
                            context += f"    - –ú–µ—Å—è—Ü—ã: {', '.join(date_analysis['month_names'])}\n"
                            context += f"    - –ó–∞–ø–∏—Å–∏ –ø–æ –º–µ—Å—è—Ü–∞–º: {date_analysis['records_per_month']}\n"
                            context += f"    - –ó–∞–ø–∏—Å–∏ –ø–æ –≥–æ–¥–∞–º: {date_analysis['records_per_year']}\n"

            if info['text_columns']:
                context += f"\nüìù –¢–ï–ö–°–¢–û–í–´–ï –ö–û–õ–û–ù–ö–ò: {', '.join(info['text_columns'])}\n"
                for col in info['text_columns']:
                    if col in info['column_analysis']:
                        analysis = info['column_analysis'][col]
                        if 'sample_values' in analysis:
                            context += f"  - {col}: –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π: {', '.join(map(str, analysis['sample_values'][:5]))}\n"
                            if 'avg_length' in analysis:
                                context += f"    (—Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {analysis['avg_length']:.1f} —Å–∏–º–≤–æ–ª–æ–≤)\n"

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
            if info['data_quality']['problematic_columns']:
                context += f"\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ù–´–ï –ö–û–õ–û–ù–ö–ò (–º–Ω–æ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π):\n"
                for col in info['data_quality']['problematic_columns']:
                    missing_info = info['missing_values'][col]
                    context += f"  - {col}: {missing_info['count']} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö ({missing_info['percent']:.1f}%)\n"

            if info['data_quality']['high_quality_columns']:
                context += f"\n‚úÖ –í–´–°–û–ö–û–ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –ö–û–õ–û–ù–ö–ò (–º–∞–ª–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π):\n"
                context += f"  {', '.join(info['data_quality']['high_quality_columns'])}\n"

        context += f"""

        üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
        1. –ò—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        2. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞—Ç—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        3. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        4. –û–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –æ–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –º–µ–∂–¥—É –ª–∏—Å—Ç–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        5. –£—á–∏—Ç—ã–≤–∞–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        6. üß† –ò–°–ü–û–õ–¨–ó–£–ô –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–£–Æ –ò–ù–§–û–†–ú–ê–¶–ò–Æ: –æ–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è, –±—ñ–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–æ–∂–ª–∏–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
        7. üéØ –£–ß–ò–¢–´–í–ê–ô –ï–î–ò–ù–ò–¶–´ –ò–ó–ú–ï–†–ï–ù–ò–Ø: –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è, –≤–∫–ª—é—á–∞–π –∏—Ö –≤ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        8. üìä –í–´–ë–ò–†–ê–ô –ü–û–î–•–û–î–Ø–©–ò–ï –û–ü–ï–†–ê–¶–ò–ò: –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –∏—Ö —Å–µ–º–∞–Ω—Ç–∏–∫–µ
        
        üöÄ –£–õ–£–ß–®–ï–ù–ù–û–ï –ü–û–ù–ò–ú–ê–ù–ò–ï –î–ê–ù–ù–´–•:
        –¢–µ–ø–µ—Ä—å —É —Ç–µ–±—è –µ—Å—Ç—å –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç:
        - –õ—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –¥–∞–Ω–Ω—ã—Ö
        - –í—ã–±–∏—Ä–∞—Ç—å –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞
        - –î–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        - –£—á–∏—Ç—ã–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        
        –î–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        –û—Ç–≤–µ—á–∞–π –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º —è–∑—ã–∫–µ.
        """

        return context

    def _normalize_region_name(self, region_name: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM
        """
        # –ï—Å–ª–∏ —Ä–µ–≥–∏–æ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ None, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not region_name:
            return region_name

        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
            prompt = ChatPromptTemplate.from_messages([
                SystemMessage(content="""
                –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–µ–æ–≥—Ä–∞—Ñ–∏–∏ –£–∫—Ä–∞–∏–Ω—ã. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤ –£–∫—Ä–∞–∏–Ω—ã.
                –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø–µ—Ä–µ–≤–µ–¥–∏ –µ–≥–æ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π.
                –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º, –æ—Å—Ç–∞–≤—å –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å.
                –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –£–∫—Ä–∞–∏–Ω—ã, –≤–µ—Ä–Ω–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.

                –ü—Ä–∏–º–µ—Ä—ã:
                "–∫–∏–µ–≤" -> "–ö–∏—ó–≤"
                "–ª—å–≤–æ–≤" -> "–õ—å–≤—ñ–≤"
                "—Ö–∞—Ä—å–∫–æ–≤" -> "–•–∞—Ä–∫—ñ–≤"
                "–æ–¥–µ—Å—Å–∞" -> "–û–¥–µ—Å–∞"
                "–¥–Ω–µ–ø—Ä" -> "–î–Ω—ñ–ø—Ä–æ"
                "–∑–∞–ø–æ—Ä–æ–∂—å–µ" -> "–ó–∞–ø–æ—Ä—ñ–∂–∂—è"
                "–≤–∏–Ω–Ω–∏—Ü–∞" -> "–í—ñ–Ω–Ω–∏—Ü—è"
                "–ø–æ–ª—Ç–∞–≤–∞" -> "–ü–æ–ª—Ç–∞–≤–∞"
                "–ö–∏—ó–≤" -> "–ö–∏—ó–≤"
                "–õ—å–≤—ñ–≤" -> "–õ—å–≤—ñ–≤"

                –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
                """),
                HumanMessage(content=f"–ù–æ—Ä–º–∞–ª–∏–∑—É–π –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞: {region_name}")
            ])

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
            response = self.llm.invoke(prompt)
            normalized_region = response.content.strip()

            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            if not normalized_region or len(normalized_region) > 50:
                return region_name

            return normalized_region

        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç —Å —Å–ª–æ–≤–∞—Ä–µ–º
            region_mapping = {
                "–∫–∏–µ–≤": "–ö–∏—ó–≤",
                "–ª—å–≤–æ–≤": "–õ—å–≤—ñ–≤",
                "—Ö–∞—Ä—å–∫–æ–≤": "–•–∞—Ä–∫—ñ–≤",
                "–æ–¥–µ—Å—Å–∞": "–û–¥–µ—Å–∞",
                "–¥–Ω–µ–ø—Ä": "–î–Ω—ñ–ø—Ä–æ",
                "–∑–∞–ø–æ—Ä–æ–∂—å–µ": "–ó–∞–ø–æ—Ä—ñ–∂–∂—è",
                "–≤–∏–Ω–Ω–∏—Ü–∞": "–í—ñ–Ω–Ω–∏—Ü—è",
                "–ø–æ–ª—Ç–∞–≤–∞": "–ü–æ–ª—Ç–∞–≤–∞"
            }

            normalized = region_name.lower().strip()
            return region_mapping.get(normalized, region_name)

    def _normalize_date_reference(self, text: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–∞—Ç –∏ –º–µ—Å—è—Ü–µ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –¢–µ–∫—Å—Ç —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –º–µ—Å—è—Ü–µ–≤
        """
        if not text:
            return text

        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
            prompt = ChatPromptTemplate.from_messages([
                SystemMessage(content="""
                –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
                –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∑–∞–º–µ–Ω–∏ –∏—Ö –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç.
                –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º, –æ—Å—Ç–∞–≤—å –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å.
                –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤, –æ—Å—Ç–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç –æ—Å—Ç–∞–≤—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

                –ü—Ä–∏–º–µ—Ä—ã:
                "—è–Ω–≤–∞—Ä—å" -> "—Å—ñ—á–µ–Ω—å"
                "—Ñ–µ–≤—Ä–∞–ª—å" -> "–ª—é—Ç–∏–π"
                "–º–∞—Ä—Ç" -> "–±–µ—Ä–µ–∑–µ–Ω—å"
                "–∞–ø—Ä–µ–ª—å" -> "–∫–≤—ñ—Ç–µ–Ω—å"
                "–º–∞–π" -> "—Ç—Ä–∞–≤–µ–Ω—å"
                "–∏—é–Ω—å" -> "—á–µ—Ä–≤–µ–Ω—å"
                "–∏—é–ª—å" -> "–ª–∏–ø–µ–Ω—å"
                "–∞–≤–≥—É—Å—Ç" -> "—Å–µ—Ä–ø–µ–Ω—å"
                "—Å–µ–Ω—Ç—è–±—Ä—å" -> "–≤–µ—Ä–µ—Å–µ–Ω—å"
                "–æ–∫—Ç—è–±—Ä—å" -> "–∂–æ–≤—Ç–µ–Ω—å"
                "–Ω–æ—è–±—Ä—å" -> "–ª–∏—Å—Ç–æ–ø–∞–¥"
                "–¥–µ–∫–∞–±—Ä—å" -> "–≥—Ä—É–¥–µ–Ω—å"

                –í–µ—Ä–Ω–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –º–µ—Å—è—Ü–µ–≤.
                """),
                HumanMessage(content=f"–ù–æ—Ä–º–∞–ª–∏–∑—É–π –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ –≤ —Ç–µ–∫—Å—Ç–µ: {text}")
            ])

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
            response = self.llm.invoke(prompt)
            normalized_text = response.content.strip()

            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            if not normalized_text or len(normalized_text) > len(text) * 2:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
                return self._normalize_date_reference_fallback(text)

            return normalized_text

        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            return self._normalize_date_reference_fallback(text)

    def _normalize_date_reference_fallback(self, text: str) -> str:
        """
        –ó–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Å—è—Ü–µ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä—è
        """
        month_mapping = {
            "—è–Ω–≤–∞—Ä—å": "—Å—ñ—á–µ–Ω—å",
            "—è–Ω–≤–∞—Ä—è": "—Å—ñ—á–Ω—è",
            "—è–Ω–≤–∞—Ä–µ": "—Å—ñ—á–Ω—ñ",
            "—Ñ–µ–≤—Ä–∞–ª—å": "–ª—é—Ç–∏–π",
            "—Ñ–µ–≤—Ä–∞–ª—è": "–ª—é—Ç–æ–≥–æ",
            "—Ñ–µ–≤—Ä–∞–ª–µ": "–ª—é—Ç–æ–º—É",
            "–º–∞—Ä—Ç": "–±–µ—Ä–µ–∑–µ–Ω—å",
            "–º–∞—Ä—Ç–∞": "–±–µ—Ä–µ–∑–Ω—è",
            "–º–∞—Ä—Ç–µ": "–±–µ—Ä–µ–∑–Ω—ñ",
            "–∞–ø—Ä–µ–ª—å": "–∫–≤—ñ—Ç–µ–Ω—å",
            "–∞–ø—Ä–µ–ª—è": "–∫–≤—ñ—Ç–Ω—è",
            "–∞–ø—Ä–µ–ª–µ": "–∫–≤—ñ—Ç–Ω—ñ",
            "–º–∞–π": "—Ç—Ä–∞–≤–µ–Ω—å",
            "–º–∞—è": "—Ç—Ä–∞–≤–Ω—è",
            "–º–∞–µ": "—Ç—Ä–∞–≤–Ω—ñ",
            "–∏—é–Ω—å": "—á–µ—Ä–≤–µ–Ω—å",
            "–∏—é–Ω—è": "—á–µ—Ä–≤–Ω—è",
            "–∏—é–Ω–µ": "—á–µ—Ä–≤–Ω—ñ",
            "–∏—é–ª—å": "–ª–∏–ø–µ–Ω—å",
            "–∏—é–ª—è": "–ª–∏–ø–Ω—è",
            "–∏—é–ª–µ": "–ª–∏–ø–Ω—ñ",
            "–∞–≤–≥—É—Å—Ç": "—Å–µ—Ä–ø–µ–Ω—å",
            "–∞–≤–≥—É—Å—Ç–∞": "—Å–µ—Ä–ø–Ω—è",
            "–∞–≤–≥—É—Å—Ç–µ": "—Å–µ—Ä–ø–Ω—ñ",
            "—Å–µ–Ω—Ç—è–±—Ä—å": "–≤–µ—Ä–µ—Å–µ–Ω—å",
            "—Å–µ–Ω—Ç—è–±—Ä—è": "–≤–µ—Ä–µ—Å–Ω—è",
            "—Å–µ–Ω—Ç—è–±—Ä–µ": "–≤–µ—Ä–µ—Å–Ω—ñ",
            "–æ–∫—Ç—è–±—Ä—å": "–∂–æ–≤—Ç–µ–Ω—å",
            "–æ–∫—Ç—è–±—Ä—è": "–∂–æ–≤—Ç–Ω—è",
            "–æ–∫—Ç—è–±—Ä–µ": "–∂–æ–≤—Ç–Ω—ñ",
            "–Ω–æ—è–±—Ä—å": "–ª–∏—Å—Ç–æ–ø–∞–¥",
            "–Ω–æ—è–±—Ä—è": "–ª–∏—Å—Ç–æ–ø–∞–¥–∞",
            "–Ω–æ—è–±—Ä–µ": "–ª–∏—Å—Ç–æ–ø–∞–¥—ñ",
            "–¥–µ–∫–∞–±—Ä—å": "–≥—Ä—É–¥–µ–Ω—å",
            "–¥–µ–∫–∞–±—Ä—è": "–≥—Ä—É–¥–Ω—è",
            "–¥–µ–∫–∞–±—Ä–µ": "–≥—Ä—É–¥–Ω—ñ"
        }

        # –°–æ–∑–¥–∞–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö –º–µ—Å—è—Ü–µ–≤
        pattern = '|'.join(month_mapping.keys())

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–µ—Å—è—Ü–µ–≤
        def replace_month(match):
            found = match.group(0).lower()
            return month_mapping.get(found, found)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞–º–µ–Ω—ã
        result = re.sub(f'({pattern})', replace_month, text, flags=re.IGNORECASE)

        return result

    def _extract_month_from_query(self, query: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Å—è—Ü –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –Ω–æ–º–µ—Ä (01-12)
        """
        month_mapping = {
            "—Å—ñ—á–µ–Ω—å": "01", "—è–Ω–≤–∞—Ä—å": "01", "—è–Ω–≤–∞—Ä—è": "01",
            "–ª—é—Ç–∏–π": "02", "—Ñ–µ–≤—Ä–∞–ª—å": "02", "—Ñ–µ–≤—Ä–∞–ª—è": "02",
            "–±–µ—Ä–µ–∑–µ–Ω—å": "03", "–º–∞—Ä—Ç": "03", "–º–∞—Ä—Ç–∞": "03",
            "–∫–≤—ñ—Ç–µ–Ω—å": "04", "–∞–ø—Ä–µ–ª—å": "04", "–∞–ø—Ä–µ–ª—è": "04",
            "—Ç—Ä–∞–≤–µ–Ω—å": "05", "–º–∞–π": "05", "–º–∞—è": "05",
            "—á–µ—Ä–≤–µ–Ω—å": "06", "–∏—é–Ω—å": "06", "–∏—é–Ω—è": "06",
            "–ª–∏–ø–µ–Ω—å": "07", "–∏—é–ª—å": "07", "–∏—é–ª—è": "07",
            "—Å–µ—Ä–ø–µ–Ω—å": "08", "–∞–≤–≥—É—Å—Ç": "08", "–∞–≤–≥—É—Å—Ç–∞": "08",
            "–≤–µ—Ä–µ—Å–µ–Ω—å": "09", "—Å–µ–Ω—Ç—è–±—Ä—å": "09", "—Å–µ–Ω—Ç—è–±—Ä—è": "09",
            "–∂–æ–≤—Ç–µ–Ω—å": "10", "–æ–∫—Ç—è–±—Ä—å": "10", "–æ–∫—Ç—è–±—Ä—è": "10",
            "–ª–∏—Å—Ç–æ–ø–∞–¥": "11", "–Ω–æ—è–±—Ä—å": "11", "–Ω–æ—è–±—Ä—è": "11",
            "–≥—Ä—É–¥–µ–Ω—å": "12", "–¥–µ–∫–∞–±—Ä—å": "12", "–¥–µ–∫–∞–±—Ä—è": "12"
        }

        query_lower = query.lower()
        for month_name, month_num in month_mapping.items():
            if month_name in query_lower:
                return month_num
        return None

    def _create_date_filtered_prompt(self, query: str, relevant_sheets: List[str]) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–∞–º
        """
        month_num = self._extract_month_from_query(query)

        if not month_num:
            return ""

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Å—è—Ü–∞–º
        date_info = ""
        sample_data_info = ""
        first_date_col = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–∞–º–∏

        for sheet_name in relevant_sheets:
            if sheet_name in self.context["sheets_info"]:
                info = self.context["sheets_info"][sheet_name]
                if "date_analysis" in info:
                    for date_col, analysis in info["date_analysis"].items():
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–∞–º–∏
                        if first_date_col is None:
                            first_date_col = date_col
                            
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü
                        month_year_combinations = analysis.get("month_year_combinations", [])
                        records_per_month = analysis.get("records_per_month", {})

                        # –ò—â–µ–º –∑–∞–ø–∏—Å–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü
                        month_records = {}
                        for month_year, count in records_per_month.items():
                            if month_year.endswith(f"-{month_num}"):
                                month_records[month_year] = count

                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
                        if sheet_name in self.dataframes:
                            df = self.dataframes[sheet_name]
                            if date_col in df.columns:
                                sample_dates = df[date_col].dropna().head(5).tolist()

                                sample_data_info += f"""
        üìã –ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–• - {sheet_name}:
        - –ö–æ–ª–æ–Ω–∫–∞ –¥–∞—Ç—ã: '{date_col}'
        - –ü—Ä–∏–º–µ—Ä—ã –¥–∞—Ç: {sample_dates}
        - –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {df[date_col].dtype}
        """

                        if month_records:
                            date_info += f"""
        üìÖ {sheet_name} - {date_col}:
        - ‚úÖ –ù–∞–π–¥–µ–Ω—ã –∑–∞–ø–∏—Å–∏ –∑–∞ –º–µ—Å—è—Ü {month_num}: {month_records}
        - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –∑–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü: {sum(month_records.values())}
        """
                        else:
                            date_info += f"""
        ‚ö†Ô∏è {sheet_name} - {date_col}:
        - ‚ùå –ù–ï–¢ –∑–∞–ø–∏—Å–µ–π –∑–∞ –º–µ—Å—è—Ü {month_num}
        - –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Å—è—Ü—ã: {', '.join(month_year_combinations)}
        - –î–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ø–æ –º–µ—Å—è—Ü–∞–º: {records_per_month}
        """

        if date_info and first_date_col:
            return f"""
        üìÖ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –î–ê–¢–ê–ú:
        –ó–∞–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è –º–µ—Å—è—Ü–∞: {month_num}

        {sample_data_info}

        {date_info}

        üí° –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–ò:
        1. –í–°–ï–ì–î–ê —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–π –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü
        2. –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü - –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
        3. –ï—Å–ª–∏ –∑–∞–ø–∏—Å–µ–π –Ω–µ—Ç - —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        4. –ò—Å–ø–æ–ª—å–∑—É–π pandas –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: df[df['{first_date_col}'].dt.month == {month_num}]
        5. –ò–ª–∏ —Ñ–∏–ª—å—Ç—Ä—É–π –ø–æ —Å—Ç—Ä–æ–∫–µ: df[df['{first_date_col}'].str.contains('2024-{month_num}')]
        6. –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Å—è—Ü–µ–≤ –∏—Å–ø–æ–ª—å–∑—É–π: df['{first_date_col}'].dt.strftime('%Y-%m').value_counts()
        7. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º
        8. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –ø—Ä–µ–¥–ª–æ–∂–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Å—è—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """

        return ""

    def _create_data_examples_prompt(self, relevant_sheets: List[str]) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        """
        examples = ""

        # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ DataFrame, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if self.combined_df is not None and not self.combined_df.empty:
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ DataFrame
            combined_sample_data = []
            for idx, row in self.combined_df.head(3).iterrows():
                row_data = {}
                for col in self.combined_df.columns:
                    value = row[col]
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫–∏
                    if isinstance(value, bool):
                        row_data[col] = str(value)
                    elif pd.isna(value):
                        row_data[col] = "NaN"
                    else:
                        row_data[col] = str(value)
                combined_sample_data.append(row_data)

            examples += f"""
        üìä –ü–†–ò–ú–ï–†–´ –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–•:
        - –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(self.combined_df)} —Å—Ç—Ä–æ–∫, {len(self.combined_df.columns)} –∫–æ–ª–æ–Ω–æ–∫
        - –ö–æ–ª–æ–Ω–∫–∏: {list(self.combined_df.columns)}
        - –í–ê–ñ–ù–û: –ö–æ–ª–æ–Ω–∫–∞ '–†–µ–≥—ñ–æ–Ω' —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        - –ü–µ—Ä–≤—ã–µ 3 –∑–∞–ø–∏—Å–∏:
        """

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            for i, row_data in enumerate(combined_sample_data, 1):
                examples += f"        –ó–∞–ø–∏—Å—å {i}:\n"
                for col, value in row_data.items():
                    examples += f"          {col}: {value}\n"

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö
            combined_dtypes_info = self.combined_df.dtypes.to_dict()
            examples += f"        - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\n"
            for col, dtype in combined_dtypes_info.items():
                examples += f"          {col}: {dtype}\n"

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∫–æ–ª–æ–Ω–∫–∏ '–†–µ–≥—ñ–æ–Ω'
            if '–†–µ–≥—ñ–æ–Ω' in self.combined_df.columns:
                region_values = self.combined_df['–†–µ–≥—ñ–æ–Ω'].unique().tolist()
                examples += f"        - –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ '–†–µ–≥—ñ–æ–Ω': {region_values}\n"
                examples += f"        - –ü—Ä–∏–º–µ—Ä –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏: df.groupby('–†–µ–≥—ñ–æ–Ω')['–∫–æ–ª–æ–Ω–∫–∞'].mean()\n"

        # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤
        for sheet_name in relevant_sheets:
            if sheet_name in self.dataframes:
                df = self.dataframes[sheet_name]

                # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                sample_data = []
                for idx, row in df.head(3).iterrows():
                    row_data = {}
                    for col in df.columns:
                        value = row[col]
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç—Ä–æ–∫–∏
                        if isinstance(value, bool):
                            row_data[col] = str(value)
                        elif pd.isna(value):
                            row_data[col] = "NaN"
                        else:
                            row_data[col] = str(value)
                    sample_data.append(row_data)

                examples += f"""
        üìä –ü–†–ò–ú–ï–†–´ –î–ê–ù–ù–´–• - {sheet_name}:
        - –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫
        - –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}
        - –ü–µ—Ä–≤—ã–µ 3 –∑–∞–ø–∏—Å–∏:
        """

                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                for i, row_data in enumerate(sample_data, 1):
                    examples += f"        –ó–∞–ø–∏—Å—å {i}:\n"
                    for col, value in row_data.items():
                        examples += f"          {col}: {value}\n"

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö
                dtypes_info = df.dtypes.to_dict()
                examples += f"        - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:\n"
                for col, dtype in dtypes_info.items():
                    examples += f"          {col}: {dtype}\n"

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Ö
                date_columns = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]
                if date_columns:
                    examples += f"        - –ö–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏: {date_columns}\n"
                    for date_col in date_columns:
                        sample_dates = df[date_col].dropna().head(5).astype(str).tolist()
                        examples += f"          {date_col}: {sample_dates}\n"

        return examples

    def _determine_query_type(self, query: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Args:
            query: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å

        Returns:
            –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: "single_region", "comparison", "general"
        """
        query_lower = query.lower()

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤
        comparison_keywords = [
            "–Ω–∞–π–≤–∏—â—ñ", "–Ω–∞–π–Ω–∏–∂—á—ñ", "–Ω–∞–π–∫—Ä–∞—â—ñ", "–Ω–∞–π–≥—ñ—Ä—à—ñ", "–ø–æ—Ä—ñ–≤–Ω—è–π", "—Å—Ä–∞–≤–Ω–∏",
            "—è–∫–∏–π", "—è–∫–∞", "—è–∫—ñ", "–¥–µ", "–≤ —è–∫–æ–º—É", "–≤ —è–∫—ñ–π", "–Ω–∞–π–±—ñ–ª—å—à–µ", "–Ω–∞–π–º–µ–Ω—à–µ",
            "—Ç–æ–ø", "—Ä–µ–π—Ç–∏–Ω–≥", "—Ä–∞–Ω–∂–∏—Ä—É–π", "—Å–æ—Ä—Ç—É–π", "–≤—ñ–¥ –Ω–∞–π–≤–∏—â–æ–≥–æ", "–≤—ñ–¥ –Ω–∞–π–Ω–∏–∂—á–æ–≥–æ"
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        for keyword in comparison_keywords:
            if keyword in query_lower:
                return "comparison"

        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç "–≤—Å–µ" –∏–ª–∏ "–≤—Å—ñ" - —ç—Ç–æ –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å
        if "–≤—Å—ñ" in query_lower or "–≤—Å–µ" in query_lower or "–∫–æ–∂–µ–Ω" in query_lower:
            return "general"

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –∑–∞–ø—Ä–æ—Å–æ–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
        return "comparison"

    def _find_relevant_sheets(self, query: str) -> List[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ª–∏—Å—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤
        """
        query_lower = query.lower()
        found_regions = []

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–æ—Ä–æ–¥–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
        city_keywords = {
            '–∫–∏–µ–≤': ['–∫–∏–µ–≤', '–∫–∏—î–≤', '–∫–∏–µ–≤–µ', '–∫–∏—î–≤—ñ'],
            '–ª—å–≤–æ–≤': ['–ª—å–≤–æ–≤', '–ª—å–≤—ñ–≤', '–ª—å–≤–æ–≤–µ', '–ª—å–≤–æ–≤—ñ'],
            '—Ö–∞—Ä—å–∫–æ–≤': ['—Ö–∞—Ä—å–∫–æ–≤', '—Ö–∞—Ä–∫—ñ–≤', '—Ö–∞—Ä—å–∫–æ–≤–µ', '—Ö–∞—Ä–∫–æ–≤—ñ'],
            '–æ–¥–µ—Å—Å–∞': ['–æ–¥–µ—Å—Å–∞', '–æ–¥–µ—Å–∞', '–æ–¥–µ—Å—Å–µ', '–æ–¥–µ—Å—ñ'],
            '–¥–Ω–µ–ø—Ä': ['–¥–Ω–µ–ø—Ä', '–¥–Ω—ñ–ø—Ä–æ', '–¥–Ω–µ–ø—Ä–µ', '–¥–Ω—ñ–ø—Ä—ñ'],
            '–∑–∞–ø–æ—Ä–æ–∂—å–µ': ['–∑–∞–ø–æ—Ä–æ–∂—å–µ', '–∑–∞–ø–æ—Ä—ñ–∂–∂—è', '–∑–∞–ø–æ—Ä–æ–∂—å–µ', '–∑–∞–ø–æ—Ä—ñ–∂–∂—ñ'],
            '–≤–∏–Ω–Ω–∏—Ü–∞': ['–≤–∏–Ω–Ω–∏—Ü–∞', '–≤—ñ–Ω–Ω–∏—Ü—è', '–≤–∏–Ω–Ω–∏—Ü–µ', '–≤—ñ–Ω–Ω–∏—Ü—ñ'],
            '–ø–æ–ª—Ç–∞–≤–∞': ['–ø–æ–ª—Ç–∞–≤–∞', '–ø–æ–ª—Ç–∞–≤–µ', '–ø–æ–ª—Ç–∞–≤—ñ']
        }

        # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
        for city_name, keywords in city_keywords.items():
            for keyword in keywords:
                if keyword in query_lower:
                    found_regions.append(city_name)
                    break

        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞, –∏—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ª–∏—Å—Ç—ã
        if found_regions:
            relevant_sheets = []
            for region in found_regions:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞
                normalized_region = self._normalize_region_name(region)

                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                if normalized_region in self.sheet_names:
                    relevant_sheets.append(normalized_region)
                else:
                    # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                    for sheet_name in self.sheet_names:
                        if normalized_region.lower() in sheet_name.lower() or sheet_name.lower() in normalized_region.lower():
                            relevant_sheets.append(sheet_name)
                            break

            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ª–∏—Å—Ç—ã
            return list(set(relevant_sheets))

        # –ï—Å–ª–∏ –≥–æ—Ä–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –ª–∏—Å—Ç—ã
        return self.sheet_names

    def _create_system_prompt(self, query: str, relevant_sheets: List[str]) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        """
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        enhanced_context = self._create_enhanced_context()

        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–∞–º
        date_filter_prompt = self._create_date_filtered_prompt(query, relevant_sheets)

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
        data_examples = self._create_data_examples_prompt(relevant_sheets)

        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ª–∏—Å—Ç–∞—Ö
        relevant_info = ""
        for sheet_name in relevant_sheets:
            if sheet_name in self.context["sheets_info"]:
                info = self.context["sheets_info"][sheet_name]
                relevant_info += f"""
        üéØ –†–ï–õ–ï–í–ê–ù–¢–ù–´–ô –õ–ò–°–¢: {sheet_name}
        - –°—Ç—Ä–æ–∫: {info['rows']}
        - –ö–æ–ª–æ–Ω–æ–∫: {len(info['columns'])}
        - –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(info['numeric_columns'])}
        - –î–∞—Ç–∞ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(info['date_columns'])}
        - –¢–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(info['text_columns'])}
        """

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º
                if info['numeric_columns']:
                    relevant_info += "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ß–ò–°–õ–û–í–´–ú –ö–û–õ–û–ù–ö–ê–ú:\n"
                    for col in info['numeric_columns']:
                        if col in info['column_analysis']:
                            stats = info['column_analysis'][col]
                            relevant_info += f"  - {col}: min={stats['min']}, max={stats['max']}, —Å—Ä–µ–¥–Ω–µ–µ={stats['mean']:.2f}\n"

        prompt = f"""
        ü§ñ –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É Excel –¥–∞–Ω–Ω—ã—Ö —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö.

        {enhanced_context}

        üéØ –ê–ù–ê–õ–ò–ó –ó–ê–ü–†–û–°–ê:
        –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{query}"
        –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ª–∏—Å—Ç—ã: {', '.join(relevant_sheets)}
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {len(relevant_sheets)}

        {relevant_info}

        {data_examples}

        {date_filter_prompt}

        üß† –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ï –ü–û–ù–ò–ú–ê–ù–ò–ï –ö–û–õ–û–ù–û–ö:
        –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–æ–Ω–∫–∞—Ö –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è:
        - –ó–Ω–∞—á–µ–Ω–Ω—è: —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–∞–∂–¥–∞—è –∫–æ–ª–æ–Ω–∫–∞ –≤ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        - –ö–∞—Ç–µ–≥–æ—Ä—ñ—è: –∫ –∫–∞–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—Å–∏—Ç—Å—è (—Ñ–∏–Ω–∞–Ω—Å—ã, —Ç–æ–≤–∞—Ä—ã, –∫–ª–∏–µ–Ω—Ç—ã –∏ —Ç.–¥.)
        - –ë—ñ–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç: –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞—Ö  
        - –ú–æ–∂–ª–∏–≤—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó: –∫–∞–∫–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏
        - –û–¥–∏–Ω–∏—Ü—ñ –≤–∏–º—ñ—Ä—É: –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        
        üìã –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
        1. üß† –ò–°–ü–û–õ–¨–ó–£–ô –°–ï–ú–ê–ù–¢–ò–ö–£: –≤—Å–µ–≥–¥–∞ —É—á–∏—Ç—ã–≤–∞–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
        2. –ò—Å–ø–æ–ª—å–∑—É–π –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        3. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞, —Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –ª–∏—Å—Ç–µ
        4. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ–±—â–∏–π, —Å—Ä–∞–≤–Ω–∏–≤–∞–π –¥–∞–Ω–Ω—ã–µ –º–µ–∂–¥—É –ª–∏—Å—Ç–∞–º–∏
        5. –ò—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤ (—Å—É–º–º—ã, —Å—Ä–µ–¥–Ω–∏–µ, –ø—Ä–æ—Ü–µ–Ω—Ç—ã)
        6. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞—Ç—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (—Ç—Ä–µ–Ω–¥—ã, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å)
        7. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
        8. –£—á–∏—Ç—ã–≤–∞–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º (min, max, —Å—Ä–µ–¥–Ω–µ–µ) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        9. üéØ –í–ö–õ–Æ–ß–ê–ô –ï–î–ò–ù–ò–¶–´ –ò–ó–ú–ï–†–ï–ù–ò–Ø: –≤—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –æ—Ç–≤–µ—Ç–∞—Ö
        10. üìä –í–´–ë–ò–†–ê–ô –ü–û–î–•–û–î–Ø–©–ò–ï –û–ü–ï–†–ê–¶–ò–ò: –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
        11. –û—Ç–≤–µ—á–∞–π –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º —è–∑—ã–∫–µ
        12. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ –≤—ã–≤–æ–¥—ã
        13. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, –¥–µ–ª–∞–π —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏

        üí° –°–¢–†–ê–¢–ï–ì–ò–Ø –û–¢–í–ï–¢–ê:
        - –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, —Ç—Ä–µ–Ω–¥, –ø–æ–∏—Å–∫)
        - –í—ã–±–µ—Ä–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        - –ò—Å–ø–æ–ª—å–∑—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (sum, mean, count, groupby)
        - –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –æ–¥–∏–Ω —Ä–µ–≥–∏–æ–Ω, –¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        - –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω–æ–≤, —Å—Ä–∞–≤–Ω–∏–≤–∞–π –∏—Ö
        - –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã, –¥–∞–π –æ–±—â—É—é –∫–∞—Ä—Ç–∏–Ω—É
        - –í–ê–ñ–ù–û: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º–µ—Å—è—Ü–∞, –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü

        üîÑ –†–ê–ë–û–¢–ê –° –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò:
        - –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–∫—É '–†–µ–≥—ñ–æ–Ω', –∏—Å–ø–æ–ª—å–∑—É–π –µ—ë –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        - –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π: df.groupby('–†–µ–≥—ñ–æ–Ω')['–∫–æ–ª–æ–Ω–∫–∞'].agg(['mean', 'max', 'min'])
        - –î–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π: df.groupby('–†–µ–≥—ñ–æ–Ω')['–∫–æ–ª–æ–Ω–∫–∞'].mean().sort_values(ascending=False)
        - –í—Å–µ–≥–¥–∞ –≥—Ä—É–ø–ø–∏—Ä—É–π –ø–æ —Ä–µ–≥–∏–æ–Ω—É –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏

        üìÖ –†–ê–ë–û–¢–ê –° –î–ê–¢–ê–ú–ò:
        - –í–°–ï–ì–î–ê —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–π –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        - –ò—Å–ø–æ–ª—å–∑—É–π df['–∫–æ–ª–æ–Ω–∫–∞_–¥–∞—Ç—ã'].dt.month –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Å—è—Ü–∞–º
        - –ò—Å–ø–æ–ª—å–∑—É–π df['–∫–æ–ª–æ–Ω–∫–∞_–¥–∞—Ç—ã'].dt.year –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≥–æ–¥–∞–º
        - –î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –∏—Å–ø–æ–ª—å–∑—É–π: df['–∫–æ–ª–æ–Ω–∫–∞_–¥–∞—Ç—ã'].dt.strftime('%Y-%m').value_counts()
        - –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ—Ç, —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        - –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–π –ø—Ä–∏–º–µ—Ä—ã –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –≤ –æ—Ç–≤–µ—Ç–µ
        - –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Å—è—Ü–∞–º –í–°–ï–ì–î–ê —Å–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–≤–∞–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame:
          filtered_df = df[df['–∫–æ–ª–æ–Ω–∫–∞_–¥–∞—Ç—ã'].dt.month == –Ω–æ–º–µ—Ä_–º–µ—Å—è—Ü–∞]
        - –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–π —Ä–∞–∑–º–µ—Ä: if len(filtered_df) > 0:
        - –ò —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–º –≤—ã–ø–æ–ª–Ω—è–π —Ä–∞—Å—á–µ—Ç—ã —Å filtered_df, –ù–ï —Å month_filtered_df –∏–ª–∏ –¥—Ä—É–≥–∏–º–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
        """

        return prompt

    def chat(self, query: str) -> str:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å —á–∞—Ç-–±–æ—Ç–æ–º
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤

        Args:
            query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –û—Ç–≤–µ—Ç —á–∞—Ç-–±–æ—Ç–∞
        """
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
            normalized_query = self._normalize_date_reference(query)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
            query_type = self._determine_query_type(normalized_query)

            # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ª–∏—Å—Ç—ã
            relevant_sheets = self._find_relevant_sheets(normalized_query)

            print(f"üîç –ù–∞–π–¥–µ–Ω—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ª–∏—Å—Ç—ã: {relevant_sheets}")
            print(f"üìã –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_type}")

            # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self._create_system_prompt(normalized_query, relevant_sheets)

            # –°—Ü–µ–Ω–∞—Ä–∏–π 1: –û–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–≥–∏–æ–Ω
            if len(relevant_sheets) == 1:
                sheet_name = relevant_sheets[0]
                if sheet_name in self.agents:
                    print(f"üéØ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω: {sheet_name}")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–ø—Ä–æ—Å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤
                    month_in_query = self._extract_month_from_query(normalized_query)
                    month_instructions = ""
                    if month_in_query:
                        month_instructions = f"""

–ö–†–ò–¢–ò–ß–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–ò –ü–û –ú–ï–°–Ø–¶–ê–ú:
1. –í–°–ï–ì–î–ê —Å–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–≤–∞–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame: filtered_df = df[df['–∫–æ–ª–æ–Ω–∫–∞_–¥–∞—Ç—ã'].dt.month == {month_in_query}]
2. –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–π —Ä–∞–∑–º–µ—Ä: if len(filtered_df) > 0:
3. –í—ã–ø–æ–ª–Ω—è–π —Ä–∞—Å—á–µ—Ç—ã —Ç–æ–ª—å–∫–æ —Å filtered_df, –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–∏–ø–∞ month_filtered_df
4. –ü—Ä–∏–º–µ—Ä —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã: filtered_df['–¶—ñ–Ω–∞ (‚Ç¥)'].mean()
5. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, —Å–æ–æ–±—â–∏ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü
"""
                    
                    enhanced_query = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}\n\n–ó–∞–ø—Ä–æ—Å: {normalized_query}{month_instructions}"
                    result = self.agents[sheet_name].invoke(enhanced_query)
                    return result['output']

            # –°—Ü–µ–Ω–∞—Ä–∏–π 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame)
            elif query_type == "comparison" and self.combined_agent:
                print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤")

                # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º
                if len(relevant_sheets) < len(self.sheet_names):
                    filtered_df = self.combined_df[self.combined_df['–†–µ–≥—ñ–æ–Ω'].isin(relevant_sheets)]
                    if not filtered_df.empty:
                        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        temp_agent = create_pandas_dataframe_agent(
                            self.llm,
                            filtered_df,
                            verbose=False,
                            agent_type=AgentType.OPENAI_FUNCTIONS,
                            allow_dangerous_code=True
                        )
                        enhanced_query = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}

–ó–∞–ø—Ä–æ—Å: {normalized_query}

–í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–∫—É '–†–µ–≥—ñ–æ–Ω' –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º. 
–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏.
–ü—Ä–∏–º–µ—Ä: df.groupby('–†–µ–≥—ñ–æ–Ω')['–¶—ñ–Ω–∞ (‚Ç¥)'].mean() - –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {', '.join(filtered_df['–†–µ–≥—ñ–æ–Ω'].unique())}"""
                        result = temp_agent.invoke(enhanced_query)
                        return result['output']

                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame
                enhanced_query = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}

–ó–∞–ø—Ä–æ—Å: {normalized_query}

–í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–∫—É '–†–µ–≥—ñ–æ–Ω' –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º. 
–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏.
–ü—Ä–∏–º–µ—Ä: df.groupby('–†–µ–≥—ñ–æ–Ω')['–¶—ñ–Ω–∞ (‚Ç¥)'].mean() - –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {', '.join(self.combined_df['–†–µ–≥—ñ–æ–Ω'].unique())}"""
                result = self.combined_agent.invoke(enhanced_query)
                return result['output']

            # –°—Ü–µ–Ω–∞—Ä–∏–π 3: –ù–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ (–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            elif len(relevant_sheets) < len(self.sheet_names):
                print(f"üéØ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {relevant_sheets}")
                responses = {}
                for sheet_name in relevant_sheets:
                    if sheet_name in self.agents:
                        enhanced_query = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}\n\n–ó–∞–ø—Ä–æ—Å: {normalized_query}"
                        result = self.agents[sheet_name].invoke(enhanced_query)
                        responses[sheet_name] = result['output']

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ç–≤–µ—Ç—ã –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º
                if len(responses) == 1:
                    return list(responses.values())[0]
                else:
                    combined_response = f"üìä –ê–Ω–∞–ª–∏–∑ –ø–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–∞–º ({len(responses)} —Ä–µ–≥–∏–æ–Ω–æ–≤):\n\n"
                    for region, response in responses.items():
                        combined_response += f"üèôÔ∏è {region}:\n{response}\n\n"
                    return combined_response

            # –°—Ü–µ–Ω–∞—Ä–∏–π 4: –û–±—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ –≤—Å–µ–º —Ä–µ–≥–∏–æ–Ω–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame)
            else:
                print(f"üåç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã —á–µ—Ä–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame")
                if self.combined_agent:
                    enhanced_query = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}

–ó–∞–ø—Ä–æ—Å: {normalized_query}

–í–ê–ñ–ù–û: –î–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–∫—É '–†–µ–≥—ñ–æ–Ω' –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º. 
–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ä–µ–≥–∏–æ–Ω–∞–º–∏.
–ü—Ä–∏–º–µ—Ä: df.groupby('–†–µ–≥—ñ–æ–Ω')['–¶—ñ–Ω–∞ (‚Ç¥)'].mean() - –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {', '.join(self.combined_df['–†–µ–≥—ñ–æ–Ω'].unique())}"""
                    result = self.combined_agent.invoke(enhanced_query)
                    return result['output']
                else:
                    # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É –º–µ—Ç–æ–¥—É
                    print(f"üåç Fallback: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏")
                    responses = {}
                    for sheet_name in relevant_sheets:
                        if sheet_name in self.agents:
                            enhanced_query = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_prompt}\n\n–ó–∞–ø—Ä–æ—Å: {normalized_query}"
                            result = self.agents[sheet_name].invoke(enhanced_query)
                            responses[sheet_name] = result['output']

                    combined_response = f"üåç –ê–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º —Ä–µ–≥–∏–æ–Ω–∞–º ({len(responses)} —Ä–µ–≥–∏–æ–Ω–æ–≤):\n\n"
                    for region, response in responses.items():
                        combined_response += f"üèôÔ∏è {region}:\n{response}\n\n"
                    return combined_response

        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"

    def generate_file_summary(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é LLM –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–µ
            total_rows = self.context['global_analysis']['total_rows']
            if total_rows == 0:
                return "üìÑ –§–∞–π–ª –ø—É—Å—Ç–æ–π - –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
            
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            brief_context = f"""
            –§–∞–π–ª: {os.path.basename(self.file_path)}
            –õ–∏—Å—Ç–æ–≤: {len(self.sheet_names)}
            –ù–∞–∑–≤–∞–Ω–∏—è –ª–∏—Å—Ç–æ–≤: {', '.join(self.sheet_names)}
            –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {total_rows:,}
            –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {self.context['global_analysis']['file_size_mb']:.2f} –ú–ë
            
            –¢–∏–ø—ã –∫–æ–ª–æ–Ω–æ–∫:
            - –ß–∏—Å–ª–æ–≤—ã—Ö: {self.context['global_analysis']['numeric_columns_count']}
            - –° –¥–∞—Ç–∞–º–∏: {self.context['global_analysis']['date_columns_count']}  
            - –¢–µ–∫—Å—Ç–æ–≤—ã—Ö: {self.context['global_analysis']['text_columns_count']}
            
            –û–±—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –º–µ–∂–¥—É –ª–∏—Å—Ç–∞–º–∏: {', '.join(self.context['global_analysis']['common_columns']) if self.context['global_analysis']['common_columns'] else '–ù–µ—Ç'}
            """
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Å—Ç–∞
            if self.sheet_names and self.sheet_names[0] in self.context["sheets_info"]:
                first_sheet = self.context["sheets_info"][self.sheet_names[0]]
                brief_context += f"\n\n–ü—Ä–∏–º–µ—Ä –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ –ª–∏—Å—Ç–∞ '{self.sheet_names[0]}': {', '.join(first_sheet['columns'][:5])}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Ö –µ—Å–ª–∏ –µ—Å—Ç—å
                if first_sheet['date_columns']:
                    for col in first_sheet['date_columns']:
                        if col in first_sheet.get('date_analysis', {}):
                            date_analysis = first_sheet['date_analysis'][col]
                            brief_context += f"\n–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {', '.join(date_analysis['month_names'])}"
                            break
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
            summary_prompt = f"""
            –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∏ –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º —è–∑—ã–∫–µ.
            –û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –æ–±—ä—è—Å–Ω—è—é—â–∏–º —á—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª.
            
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ:
            {brief_context}
            
            –ù–∞—á–Ω–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Å: "üìä –ß—É–¥–æ–≤–æ! –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —Ñ–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ."
            
            –ó–∞—Ç–µ–º –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏:
            - –ß—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª (–ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º, –ø—Ä–æ–¥–∞–∂–∞–º –∏ —Ç.–¥. –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ª–∏—Å—Ç–æ–≤)
            - –°–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö (—Å—Ç—Ä–æ–∫) 
            - –ö–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ –æ—Ö–≤–∞—á–µ–Ω (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã)
            - –ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –º–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
            
            –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –±–æ–ª–µ–µ 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º.
            """
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary
            llm = ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo")
            response = llm.invoke(summary_prompt)
            
            return response.content.strip()
            
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            if self.context['global_analysis']['total_rows'] == 0:
                return "üìÑ –§–∞–π–ª –ø—É—Å—Ç–æ–π - –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
            else:
                return f"üìä –ß—É–¥–æ–≤–æ! –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π —Ñ–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ. –§–∞–π–ª –º—ñ—Å—Ç–∏—Ç—å {len(self.sheet_names)} –ª–∏—Å—Ç—ñ–≤ –∑ –¥–∞–Ω–∏–º–∏ –ø–æ —Ä–µ–≥—ñ–æ–Ω–∞—Ö ({self.context['global_analysis']['total_rows']:,} –∑–∞–ø–∏—Å—ñ–≤). –¢–µ–ø–µ—Ä –≤–∏ –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç–∏ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ –¥–∞–Ω—ñ."

    def get_file_info(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        """
        return {
            "file_path": self.file_path,
            "total_sheets": len(self.sheet_names),
            "sheets": self.sheet_names,
            "structure": self.context["sheets_info"]
        }

    def get_detailed_analysis(self) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        return self._create_enhanced_context()

    def get_sheet_summary(self, sheet_name: str = None) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ –ª–∏—Å—Ç—É –∏–ª–∏ –≤—Å–µ–º –ª–∏—Å—Ç–∞–º

        Args:
            sheet_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–∏—Å—Ç–∞ (–µ—Å–ª–∏ None, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ –≤—Å–µ–º)
        """
        if sheet_name:
            if sheet_name in self.context["sheets_info"]:
                info = self.context["sheets_info"][sheet_name]
                return {
                    "sheet_name": sheet_name,
                    "rows": info["rows"],
                    "columns": info["columns"],
                    "numeric_columns": info["numeric_columns"],
                    "date_columns": info["date_columns"],
                    "text_columns": info["text_columns"],
                    "data_types": info["data_types"]
                }
            else:
                return {"error": f"–õ–∏—Å—Ç '{sheet_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        else:
            summary = {}
            for name, info in self.context["sheets_info"].items():
                summary[name] = {
                    "rows": info["rows"],
                    "columns_count": len(info["columns"]),
                    "numeric_columns": info["numeric_columns"],
                    "date_columns": info["date_columns"],
                    "text_columns": info["text_columns"]
                }
            return summary

    def get_available_regions(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
        return self.sheet_names

    def get_available_dates(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç–∞—Ö –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
        date_info = {}

        for sheet_name in self.sheet_names:
            if sheet_name in self.context["sheets_info"]:
                info = self.context["sheets_info"][sheet_name]
                if "date_analysis" in info:
                    date_info[sheet_name] = {}
                    for date_col, analysis in info["date_analysis"].items():
                        date_info[sheet_name][date_col] = {
                            "years": analysis.get("years", []),
                            "months": analysis.get("months", []),
                            "month_names": analysis.get("month_names", []),
                            "month_year_combinations": analysis.get("month_year_combinations", []),
                            "records_per_month": analysis.get("records_per_month", {}),
                            "records_per_year": analysis.get("records_per_year", {})
                        }

        return date_info

    def get_date_summary(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –¥–∞—Ç–∞–º –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        date_info = self.get_available_dates()

        if not date_info:
            return "üìÖ –í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ —Å –¥–∞—Ç–∞–º–∏"

        summary = "üìÖ –°–í–û–î–ö–ê –ü–û –î–ê–¢–ê–ú:\n\n"

        for region, date_cols in date_info.items():
            summary += f"üèôÔ∏è {region}:\n"
            for date_col, info in date_cols.items():
                summary += f"  üìä {date_col}:\n"
                summary += f"    - –ì–æ–¥—ã: {', '.join(map(str, info['years']))}\n"
                summary += f"    - –ú–µ—Å—è—Ü—ã: {', '.join(info['month_names'])}\n"
                summary += f"    - –ó–∞–ø–∏—Å–∏ –ø–æ –º–µ—Å—è—Ü–∞–º: {info['records_per_month']}\n"
                summary += f"    - –ó–∞–ø–∏—Å–∏ –ø–æ –≥–æ–¥–∞–º: {info['records_per_year']}\n"
            summary += "\n"

        return summary

    def query_specific_region(self, region: str, query: str) -> str:
        """
        –ó–∞–ø—Ä–æ—Å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ä–µ–≥–∏–æ–Ω—É

        Args:
            region: –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞
            query: –í–æ–ø—Ä–æ—Å

        Returns:
            –û—Ç–≤–µ—Ç
        """
        normalized_region = self._normalize_region_name(region)
        normalized_query = self._normalize_date_reference(query)

        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        if normalized_region in self.sheet_names:
            return self.chat(f"–î–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {normalized_region}: {normalized_query}")

        # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        for sheet_name in self.sheet_names:
            if normalized_region.lower() in sheet_name.lower():
                return self.chat(f"–î–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {sheet_name}: {normalized_query}")

        return f"–†–µ–≥–∏–æ–Ω '{region}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {', '.join(self.sheet_names)}"


def create_smart_excel_chatbot(file_path: str) -> SmartExcelChatbot:
    """
    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä —É–º–Ω–æ–≥–æ —á–∞—Ç-–±–æ—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel —Ñ–∞–π–ª–æ–º

    Args:
        file_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É

    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä SmartExcelChatbot
    """
    return SmartExcelChatbot(file_path)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏
    file_path = "../../data/–¥–µ—Ç–∞–ª—å–Ω—ñ_–ø—Ä–æ–¥–∞–∂—ñ_–ø–æ_—Ä–µ–≥—ñ–æ–Ω–∞—Ö.xlsx"

    try:
        # –°–æ–∑–¥–∞–µ–º —á–∞—Ç-–±–æ—Ç–∞
        chatbot = create_smart_excel_chatbot(file_path)

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        info = chatbot.get_file_info()
        print(f"üìä –§–∞–π–ª: {info['file_path']}")
        print(f"üìã –õ–∏—Å—Ç–æ–≤: {info['total_sheets']}")
        print(f"üèôÔ∏è –†–µ–≥–∏–æ–Ω—ã: {', '.join(info['sheets'])}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        print("\n=== –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ ===")
        detailed_analysis = chatbot.get_detailed_analysis()
        print(detailed_analysis)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print("\n=== –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê ===")
        summary = chatbot.get_sheet_summary()
        for sheet_name, sheet_info in summary.items():
            print(f"üìã {sheet_name}: {sheet_info['rows']} —Å—Ç—Ä–æ–∫, {sheet_info['columns_count']} –∫–æ–ª–æ–Ω–æ–∫")
            print(f"   –ß–∏—Å–ª–æ–≤—ã–µ: {len(sheet_info['numeric_columns'])}")
            print(f"   –î–∞—Ç—ã: {len(sheet_info['date_columns'])}")
            print(f"   –¢–µ–∫—Å—Ç–æ–≤—ã–µ: {len(sheet_info['text_columns'])}")

        # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤
        print("\n=== –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ ===")

        # –ó–∞–ø—Ä–æ—Å 1: –ü–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ä–µ–≥–∏–æ–Ω—É (—Å —Ä—É—Å—Å–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º)
        print("\n1. –ó–∞–ø—Ä–æ—Å –ø–æ –ö–∏–µ–≤—É:")
        response = chatbot.chat("–Ø–∫–∞ —Å–µ—Ä–µ–¥–Ω—è —Ü—ñ–Ω–∞ –∑–∞ –°–µ–Ω—Ç—è–±—Ä—å –≤ –ö–∏–µ–≤–µ?")
        print(response)

        # –ó–∞–ø—Ä–æ—Å 2: –û–±—â–∏–π –∑–∞–ø—Ä–æ—Å
        print("\n2. –û–±—â–∏–π –∑–∞–ø—Ä–æ—Å:")
        response = chatbot.chat("–ü–æ—Ä—ñ–≤–Ω—è–π —Ü—ñ–Ω–∏ –∑–∞ –°–µ–Ω—Ç—è–±—Ä—å –ø–æ –≤—Å—ñ—Ö —Ä–µ–≥—ñ–æ–Ω–∞—Ö")
        print(response)

        # –ó–∞–ø—Ä–æ—Å 3: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
        print("\n3. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö:")
        response = chatbot.chat("–Ø–∫—ñ –Ω–∞–π–ø–æ–ø—É–ª—è—Ä–Ω—ñ—à—ñ —Ç–æ–≤–∞—Ä–∏?")
        print(response)

        # –ó–∞–ø—Ä–æ—Å 4: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        print("\n4. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:")
        response = chatbot.chat("–ü–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å—ñ—Ö —á–∏—Å–ª–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö")
        print(response)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}") 